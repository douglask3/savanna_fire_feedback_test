{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table style=\"width: 100%; border-collapse: collapse;\" border=\"0\">\n",
    "<tr>\n",
    "<td><b>Created:</b> Tuesday 7 August 2018</td>\n",
    "<td style=\"text-align: right;\"><a href=\"https://github.com/douglask3/savanna_fire_feedback_test\">github.com/douglask3/savanna_fire_feedback_test</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<font face=\"Times\">\n",
    "<br>\n",
    "<h1>Quantifying the uncertainity in climate potentials and mortality using Bayesian inference</h1>\n",
    "<h2>Part 2: Bayesian inference</h2>\n",
    "<br>\n",
    "<br>\n",
    "<sup>1,* </sup>Douglas Kelley, \n",
    "<sup>1 </sup>France Gerard, \n",
    "<sup>2 </sup>Rhys Whitley, \n",
    "<sup>3 </sup>Elmar Veenendaal\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<sup>1 </sup>Centre for Ecology and Hydrology, Maclean Building, Crowmarsh Gifford, Wallingford, Oxfordshire, United Kingdom\n",
    "<br>\n",
    "<sup>2 </sup>Natural Perils Pricing, Commercial & Consumer Portfolio & Pricing, Suncorp Group, Sydney, Australia\n",
    "<br>\n",
    "<sup>3 </sup>Wageningen Univsersity, Wageningen UR\n",
    "<br>\n",
    "<br>\n",
    "<h3>Summary</h3>\n",
    "<hr>\n",
    "<p> \n",
    "This notebook aims to quantify the model parameters of a global tree cover model model. Tree Cover is calculated as a product  precipitation, tempurature  and radiation controls describing large scale climate potetials, and mortality from fire, seasonal drought, tempuature and people, and exlusion from land use modulate tree cover. This limitation model for tree cover (LimTREE) is optimized using a Bayesian Inference framework, which provides a probability distribution for the models paramters, and allows us to describe the magnitude and relative impact of controls and varaibles in terms of probabilities. Here, we cover model description and optimization.\n",
    "</p>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<i>Python code and calculations below</i>\n",
    "<br>\n",
    "</font>\n",
    "</center>\n",
    "<hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model description\n",
    "Tree Cover ($T$) is calculated as a product five controls. Mean annual precipitation ($MAP$), mean annual tempurature ($MAT$) and incoming shortwave radiation ($SW$) represent three liberative controls on  $T$, i.e, increases in any of the variables lead to an increase in $T$. Mortality ($M$), which combines varaibles describing fire (represented by burnt area - $F$), drought (by number of dry days, $D$) and extreme seasonal tempuratures (by mean maximum temperuature of the hottest month, $MMxT$), and land use exclusion ($E$) from fractional urban ($U$), crop ($C$) and pasture ($P$) cover are suppresive controls. Each control is expressed as a linear combination of their respective variables and represented by a simple logistic curve:\n",
    "\n",
    "\\begin{equation}\n",
    "    f(x) = \\frac{1}{1 + e^{-k\\cdot(x-x_0)}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "    T &=& F_{max} \\cdot \\prod f(x) \\\\[1em]\n",
    "\\end{eqnarray}\n",
    "\n",
    "Where $f(x)$ is the limitation imposed by control $x = MAP, MAT, SW, M, E$ and $T_{max}$ is a maximum permitted monthly burnt area used to aid our model optimization. $x_0$ is the value of control $x$ when it imposes a limitation of 50\\% on burnt area (i.e,$f(x) = 0.5$), and $k$ is the steepness of the logistic curve, equal to Â¼ of the gradient at $x = x_0$. $k > 0$ for $MAP$, $MAT$ and $SW$, where $T$ increases with the control, whereas $k < 0$ for $M$ and $E$, for which $T$ decreases. Each suppresive control\n",
    "is represented by a combination of variables ($x_i$) weighted by their respective influence ($v_i$). Where possible, units are consistent across variables within each control, and as such the combined variables are normalised to maintain these units:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "    x &=& \\sum v_i \\cdot x_i / \\sum v_i  \\\\[1em]\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "    v_i = 1\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "\n",
    "This leaves 14 free parameters that need to be optimised against observations of burnt area.\n",
    "\n",
    "Now lets get this coded up in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from   io     import StringIO\n",
    "import numpy  as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import pymc3  as pm3 \n",
    "from   pymc3.backends import SQLite\n",
    "from   scipy  import optimize\n",
    "from   theano import tensor as tt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# setup nice plotting\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# paths and parameters\n",
    "sample_pc     = 20\n",
    "nIterations   = 10000\n",
    "nJobs         = 1\n",
    "nChains       = 2\n",
    "outPath       = \"../data/vegFracControls.csv\"\n",
    "param_outpath = '../outputs/params-paper1-logitnorm-newPop-full-c1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npLog0 (x):\n",
    "    return [np.log(i) if i > 0 else 0.0000001 for i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.1 Fire limitation model definition\n",
    "\n",
    "Could possibly contain this in a class object, but I'm not sure theano can instantiate the object to be used by the GPU. If I've made absolutely no sense just then, then I would leave the following as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace as browser\n",
    "\n",
    "def tt_sigmoid(x, k, x0):\n",
    "    \"\"\"\n",
    "    Sigmoid function to describe limitation using tensor\n",
    "    \"\"\"\n",
    "    return 1.0/(1.0 + tt.exp(-k*(x - x0)))\n",
    "\n",
    "\n",
    "def MAP(map):\n",
    "    \"\"\"\n",
    "    Definition to describe precip: while we are just returning input for now,\n",
    "    we include climate potential functions for capability to be modified later.\n",
    "    \"\"\"\n",
    "    return map\n",
    "    \n",
    "\n",
    "def MAT(mat):#, min_mat, max_mat):\n",
    "    \"\"\"\n",
    "    Definition to describe temp.\n",
    "    \"\"\"\n",
    "    #mat = mat - min_mat\n",
    "    #mat = mat / (max_mat - min_mat)\n",
    "    #mat = tt.clip(mat, 0.0000001, 100000)\n",
    "    #mat = tt.log(mat)\n",
    "    return mat\n",
    "\n",
    "\n",
    "def SW(sw1, sw2, d):\n",
    "    \"\"\"\n",
    "    Definition to describe short wave\n",
    "    \"\"\"\n",
    "    return sw1 + d * sw2 /(1.0 + d)\n",
    "\n",
    "\n",
    "def mortality(fire, drought, maxTemp, wind, v_drought, v_maxTemp, v_wind, #v_pop,pop_density\n",
    "              p_fire, p_drought):#, min_maxTemp, max_maxTemp, p_maxTemp):\n",
    "    \"\"\"\n",
    "    Definition of mortality\n",
    "    \"\"\"\n",
    "    #maxTemp = maxTemp - min_maxTemp\n",
    "    #maxTemp = maxTemp / (max_maxTemp - min_maxTemp)\n",
    "    #maxTemp = tt.clip(maxTemp, 0.0, 1.0)\n",
    "    #maxTemp = maxTemp **(p_maxTemp)\n",
    "    \n",
    "    drought = drought ** (p_drought)\n",
    "    #pop_density = 1 - tt.exp(pop_density * (-1.0/ k_popden))\n",
    "    \n",
    "    fire = fire**(p_fire)\n",
    "    mort = fire  +  v_drought * drought  +  v_maxTemp * maxTemp + v_wind * wind  #+  v_pop * pop_density\n",
    "\n",
    "    return mort / (1.0 + v_drought + v_maxTemp + v_wind)#+ v_pop)\n",
    "\n",
    "def exclusion(urban_area, crop_area, pasture_area, pop_density, v_crop, v_pas, v_pop, k_popden):\n",
    "    \"\"\"\n",
    "    Definition for the measure of fire supression\n",
    "    \"\"\"\n",
    "    pop_density = 1 - tt.exp(pop_density * (-1.0/ k_popden))\n",
    "    excl = urban_area  +  v_crop * crop_area + v_pas * pasture_area + v_pop * pop_density\n",
    "       \n",
    "    \n",
    "    return excl / (1.0 + v_crop + v_pas + v_pop)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Import data\n",
    "\n",
    "Load data and do any necessary transformation needed for the Bayesian modelling framework. We  going to load 10% of data-points. When we evalutate, that gives us 90% spare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_with_buffer(filename, line_select, **kwargs):\n",
    "    s_buf = StringIO()\n",
    "    line_select = np.sort(line_select)\n",
    "    with open(filename) as file:\n",
    "        count = -1\n",
    "        lineN = -1\n",
    "        for line in file:\n",
    "            lineN += 1\n",
    "            if lineN == 0 or lineN == line_select[count]:\n",
    "                s_buf.write(line)\n",
    "                count += 1\n",
    "                if count == len(line_select): break\n",
    "            \n",
    "    s_buf.seek(0)\n",
    "    df = pd.read_csv(s_buf,**kwargs)\n",
    "    return df\n",
    "\n",
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f): pass\n",
    "    return i + 1\n",
    "\n",
    "DATAPATH = os.path.expanduser(outPath)\n",
    "\n",
    "nlines      = file_len(DATAPATH)\n",
    "npoints     = round(sample_pc * nlines / 100)\n",
    "line_select = np.random.choice(range(0, nlines), npoints, False)\n",
    "fd          = load_with_buffer(DATAPATH, line_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a sanity check to make sure our data has imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(x, xmin = 0.00001):\n",
    "    x[x < xmin] = xmin\n",
    "    return np.log(x)\n",
    "cols = [col for col in fd.columns if \"MAP_\" in col]\n",
    "for col in cols: fd[col] = log(fd[col].values)\n",
    "fd[\"MAT\"] = log(fd[\"MAT\"].values + 273.15)\n",
    "fd[\"MTWM\"] = log(fd[\"MTWM\"].values + 273.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npLogit(x, n):\n",
    "    x = (x*(n - 1) + 0.5) /n\n",
    "    return  np.log(x/(1-x))\n",
    "    \n",
    "def ttLogit(x, n):\n",
    "    x = (x*(n - 1) + 0.5) /n\n",
    "    return tt.log(x/(1-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = fd[\"TreeCover\"].values\n",
    "obs = obs/0.8\n",
    "\n",
    "obs = np.clip(obs, 0, 1.0)\n",
    "obs = npLogit(obs, nlines)\n",
    "\n",
    "plt.hist(obs, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BurntArea                   0.000000e+00\n",
      "crop                        0.000000e+00\n",
      "MaxWind                     0.000000e+00\n",
      "buffalo                    -9.961854e-13\n",
      "cattle                     -3.542911e-12\n",
      "MADD_CMORPH                 8.693070e-02\n",
      "MADD_CRU                    6.806921e-02\n",
      "MADD_GPCC                   7.588196e-02\n",
      "MADD_MSWEP                  0.000000e+00\n",
      "MADM_CMORPH                 1.564521e-01\n",
      "MADM_CRU                    1.452650e-01\n",
      "MADM_GPCC                   0.000000e+00\n",
      "MADM_MSWEP                  1.116933e-01\n",
      "goat                       -3.191831e-12\n",
      "MAP_CMORPH                 -1.466993e-01\n",
      "MAP_CRU                    -1.151293e+01\n",
      "MAP_GPCC                   -7.957571e+00\n",
      "MAP_MSWEP                  -5.637010e+00\n",
      "MAT                         5.588140e+00\n",
      "MConc_CMORPH                8.403335e-02\n",
      "MConc_CRU                   4.647733e-03\n",
      "MConc_GPCC                  5.937037e-02\n",
      "MConc_MSWEP                 5.375389e-02\n",
      "MDDM_CMORPH                 1.846009e-01\n",
      "MDDM_CRU                    2.262804e-01\n",
      "MDDM_GPCC                   1.168477e-01\n",
      "MDDM_MSWEP                  0.000000e+00\n",
      "MTWM                        5.640259e+00\n",
      "pas                         0.000000e+00\n",
      "PopDen                      0.000000e+00\n",
      "SW                          3.350368e+01\n",
      "SW.1                        2.754113e+01\n",
      "TreeCover                   0.000000e+00\n",
      "urban                       0.000000e+00\n",
      "sheep                      -9.156653e-12\n",
      "MTCM                       -2.367143e+01\n",
      "BurntArea_GFED              0.000000e+00\n",
      "BurntArea_GFED.1            0.000000e+00\n",
      "BurntArea_meris             0.000000e+00\n",
      "BurntArea_MODIS             0.000000e+00\n",
      "BurntArea_MCD               0.000000e+00\n",
      "BurntArea_GFED_four_s       0.000000e+00\n",
      "BurntArea_GFED_four         0.000000e+00\n",
      "BurntArea_MCD_forty_five    0.000000e+00\n",
      "dtype: float64\n",
      "BurntArea                      0.916191\n",
      "crop                           0.715618\n",
      "MaxWind                       13.586535\n",
      "buffalo                      241.873400\n",
      "cattle                       378.308840\n",
      "MADD_CMORPH                    0.996879\n",
      "MADD_CRU                       1.000000\n",
      "MADD_GPCC                      1.000000\n",
      "MADD_MSWEP                     1.000000\n",
      "MADM_CMORPH                    1.000000\n",
      "MADM_CRU                       1.000000\n",
      "MADM_GPCC                      1.000000\n",
      "MADM_MSWEP                     1.000000\n",
      "goat                         612.822450\n",
      "MAP_CMORPH                     8.946462\n",
      "MAP_CRU                        8.945972\n",
      "MAP_GPCC                       8.839557\n",
      "MAP_MSWEP                      9.013157\n",
      "MAT                            5.716526\n",
      "MConc_CMORPH                   1.000000\n",
      "MConc_CRU                      1.000000\n",
      "MConc_GPCC                     1.000000\n",
      "MConc_MSWEP                    1.000000\n",
      "MDDM_CMORPH                    1.000000\n",
      "MDDM_CRU                       1.000000\n",
      "MDDM_GPCC                      1.000000\n",
      "MDDM_MSWEP                     1.000000\n",
      "MTWM                           5.765527\n",
      "pas                            0.831616\n",
      "PopDen                      6309.098000\n",
      "SW                           353.319370\n",
      "SW.1                         381.630460\n",
      "TreeCover                      0.802798\n",
      "urban                         29.084944\n",
      "sheep                        529.188230\n",
      "MTCM                          23.421429\n",
      "BurntArea_GFED                 0.916191\n",
      "BurntArea_GFED.1               0.902413\n",
      "BurntArea_meris                0.972139\n",
      "BurntArea_MODIS                0.920842\n",
      "BurntArea_MCD                  0.981236\n",
      "BurntArea_GFED_four_s          0.916191\n",
      "BurntArea_GFED_four            0.902413\n",
      "BurntArea_MCD_forty_five       0.981236\n",
      "dtype: float64\n",
      "-14723.541757034756\n"
     ]
    }
   ],
   "source": [
    "#print(fd.info())\n",
    "#print(fd.head())\n",
    "print(fd.min())\n",
    "print(fd.max())\n",
    "print(sum(obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Baysian framework\n",
    "\n",
    "A simple explanation of Baye's law is:\n",
    "\n",
    "\\begin{equation}\n",
    "    P(\\beta|X) \\propto P(\\beta)\\cdot P(X|\\beta)\n",
    "\\end{equation}\n",
    "\n",
    "where $X$ is our data (observations of some arbitrary system), and $\\beta$ our set of unexplained parameters that describe the reponse of our _proposed understanding_ of this system as it varies with $X$.\n",
    "\n",
    "### 2.3.1 Prior definitions\n",
    "Because I have no idea what the uncertainty on the hyper parameters should look like (beyond $\\beta> 0$), I've set them all as wide, familiar distrubtions, spread generously beyound what is realistic plausable. Our full prior looks like this:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "    P(x_0) &=& \\mathcal{N}(0.5, 0.5) \\\\\n",
    "    P(k_x) &=& \\mathcal{exp}(0.1) \\\\\n",
    "    P(T_{max}) = P(p_{popden}) = P(v_i) &=& \\mathcal{exp}(1) \\\\\n",
    "    P(\\sigma) &=& \\mathcal{N_{1/2}}(1) \\\\[1.5em]\n",
    "\\end{eqnarray}\n",
    "\n",
    "So our full set of piors looks something like this:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "    P(\\beta) &=& \\prod_{x=1}^{4}\\mathcal{S}(P(x_0),P(k_x), P(v_x)) \\cdot P(D_{max}) \\cdot P(\\sigma) \\\\[1.5em]  \n",
    "\\end{eqnarray}\n",
    "\n",
    "This is loosly describes a (albeit slightly skewed) Normal distribution, so we can approximate our error ($\\sigma$) with a normal distibution. \n",
    "\n",
    "Back to the code.., `pymc3` is quite funky in that it allows me to create an empty `Model()` object and just add things to it as I need them using a `with` statement. I've called our Bayesian model `tree_error` as that is what we are trying to Quantify.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nChains = nChains * nJobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutLastX(varname, mcmc_traces, ncut = 50):\n",
    "    vals = mcmc_traces.get_values(varname)\n",
    "    def subcut(vals, r, ncut = 50):\n",
    "        cut_np = (r+1) * round(len(vals)/nChains)\n",
    "        ncut = round(len(vals) * ncut / (nChains *100))\n",
    "        return vals[(cut_np - ncut):cut_np]\n",
    "    vals = [subcut(vals, r) for r in range(nChains)]\n",
    "    return np.array(vals).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_zero_inflated_normal(mu, sigma, pz, x):\n",
    "    '''return tt.sw1itch(\n",
    "        tt.lt(x, -150),\n",
    "        -p0,\n",
    "        -(1.0 - p0) *(1.0/(sigma * 2.506))*tt.exp(-0.5 * ((x-mu)/sigma)**2)\n",
    "    )\n",
    "    '''\n",
    "    return tt.switch(\n",
    "        tt.lt(x, -30),\n",
    "        tt.log(pz),\n",
    "        tt.log(1-pz) - tt.log(sigma * tt.sqrt(2*math.pi)) - ((x-mu)**2)/(2*sigma**2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pr_droughtVar(pr_dataset, drough_var, fire_dataset):\n",
    "    with pm3.Model() as tree_error:\n",
    "\n",
    "    # first for the sigmoids  \n",
    "        MAP_x0         = pm3.Normal('MAP_x0'       ,  5.0, 1.0)\n",
    "        MAP_k          = pm3.Exponential('MAP_k'        ,  1.0)\n",
    "\n",
    "        MAT_x0         = pm3.Normal('MAT_x0'   ,  0.0, 1.0)\n",
    "        MAT_k          = pm3.Exponential('MAT_k'    ,  1.0)\n",
    "\n",
    "        SW_x0          = pm3.Exponential('SW_x0'   ,  1/300.0)\n",
    "        SW_k           = pm3.Exponential('SW_k'    ,        1.5)\n",
    "\n",
    "        mort_x0        = pm3.Normal('mort_x0', 0.5, 0.5)\n",
    "        mort_k         = pm3.Exponential('mort_k' , 1.0)\n",
    "\n",
    "        ex_x0          = pm3.Normal('ex_x0', 0.5, 0.5)\n",
    "        ex_k           = pm3.Exponential('ex_k' , 1.0)\n",
    "\n",
    "        max_T          = pm3.Uniform('max_T'         ,     0.0,   0.8)\n",
    "        #pow_f          = pm3.Uniform('pow_f'         ,     0.0,    1.0)\n",
    "    # now for the hyper-parameters that describe the independent fire condition covariates\n",
    "\n",
    "        #cNpp = pm3.Uniform('cNPP', 0.0, 10)\n",
    "        v_drought  = pm3.Exponential('v_drought', 1.0)\n",
    "        v_maxTemp  = pm3.Exponential('v_maxTemp', 1.0)\n",
    "        v_wind     = pm3.Exponential('v_wind', 1.0)\n",
    "        v_popDen   = pm3.Exponential('v_popDen' , 1.0)\n",
    "        v_crop     = pm3.Exponential('v_crop'   , 1.0)\n",
    "        v_pas      = pm3.Exponential('v_pas'    , 1.0)\n",
    "\n",
    "        trans_d    = pm3.Exponential('trans_d'  , 1.0)\n",
    "        p_fire     = pm3.Exponential('p_fire', 1.0)\n",
    "        k_popden   = pm3.Exponential('k_popden' , 10.0)\n",
    "\n",
    "        p_drought    = pm3.Exponential('p_drought', 1.0)\n",
    "        #min_maxTemp  = pm3.Normal     ('min_maxTemp', 20.0, 31.34)\n",
    "        #max_maxTemp  = pm3.Normal     ('max_maxTemp', 30.0, 31.34)\n",
    "        #min_mat      = pm3.Normal     ('min_mat', 0.0, 3.0)\n",
    "        #max_mat      = pm3.Normal     ('max_mat', 15.0, 5.0)\n",
    "        #p_maxTemp    = pm3.Exponential('p_maxTemp', 1.0)\n",
    "    # describe the standard deviation in the error term\n",
    "        sigma      = pm3.HalfNormal('sigma', sd=0.1)\n",
    "        \n",
    "        p0 = pm3.Uniform('p0', 0.0, 1.0)\n",
    "        pp = pm3.Lognormal('pp', 0.0, 1.0)\n",
    "        \n",
    "\n",
    "        # transform hyper-covariates \n",
    "        MAP_var = 'MAP_' + pr_dataset\n",
    "        drght_var = drough_var + '_' + pr_dataset\n",
    "        fire_var = 'BurntArea_' + fire_dataset\n",
    "        f_precip = MAP(fd[MAP_var].values)\n",
    "        f_temp   = MAT(fd[\"MAT\"].values)#, min_mat, max_mat)\n",
    "        f_sw     = SW (fd[\"SW\"].values, fd[\"SW.1\"].values, trans_d)\n",
    "        f_mort   = mortality(fd[fire_var].values, fd[drght_var].values, fd[\"MTWM\"].values, \n",
    "                             fd['MaxWind'].values,  #fd[\"PopDen\"].values, \n",
    "                             v_drought, v_maxTemp, v_wind, #v_popDen, \n",
    "                             p_fire, p_drought)#, min_maxTemp, max_maxTemp, p_maxTemp)\n",
    "        f_exc    = exclusion(fd[\"urban\"].values, fd[\"crop\"].values, fd[\"PopDen\"].values,\n",
    "                             fd[\"pas\"].values, v_crop, v_pas, v_popDen, k_popden)\n",
    "\n",
    "        # Tree cover is assumed to be the product of the 4 sigmoid\n",
    "\n",
    "        prediction = np.product([tt_sigmoid(f_precip, MAP_k, MAP_x0), # max_T * \n",
    "                                 tt_sigmoid(f_temp, MAT_k, MAT_x0),\n",
    "                                 tt_sigmoid(f_sw, SW_k, SW_x0),\n",
    "                                 tt_sigmoid(f_mort, - mort_k, mort_x0),\n",
    "                                 tt_sigmoid(f_exc, - ex_k, ex_x0)]) #/ 0.8\n",
    "        \n",
    "        prediction = tt.clip(prediction, -0.0, 1.0)\n",
    "        #pz = 1.0 - (prediction**pp) * (1.0 - p0)\n",
    "        prediction = ttLogit(prediction, nlines)             \n",
    "        # calculate the error between observed and predicted burnt area\n",
    "        error = pm3.Normal('error', mu = prediction, sd = sigma, observed=obs)#fd[\"TreeCover\"].values)\n",
    "        #error = pm3.DensityDist(\"error\", make_zero_inflated_normal,\n",
    "        #                        observed = {\"mu\": prediction, \"sigma\": sigma, \"pz\": pz, \"x\": obs})\n",
    "           \n",
    "        # set the step-method (criteria algorithm for moving around information space)\n",
    "        step = pm3.Metropolis()\n",
    "\n",
    "        # do the sampling\n",
    "        mcmc_traces = pm3.sample(nIterations, step=step, chains = nChains)  #, njobs= nJobs\n",
    "        \n",
    "    #pm3.traceplot(mcmc_traces);\n",
    "    varnames = mcmc_traces.varnames\n",
    "    \n",
    "    vals = [cutLastX(i, mcmc_traces) for i in varnames]\n",
    "\n",
    "    vals = pd.DataFrame(np.array(vals).T, columns=varnames)\n",
    "    out_fname = param_outpath + '_' + pr_dataset + '_' + drough_var + '_' + fire_dataset + '.csv'\n",
    "    vals.to_csv(out_fname, index=False)\n",
    "    #plt.plot(vals[\"max_T\"])\n",
    "    #plt.show()\n",
    "    plt.hist(vals[\"max_T\"])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #plt.plot(vals[\"sigma\"])\n",
    "    #plt.show()\n",
    "    plt.hist(vals[\"sigma\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_pr_droughtVar('GPCC', 'MADD', 'GFED_four_s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [pp]\n",
      ">Metropolis: [p0]\n",
      ">Metropolis: [sigma]\n",
      ">Metropolis: [p_drought]\n",
      ">Metropolis: [k_popden]\n",
      ">Metropolis: [p_fire]\n",
      ">Metropolis: [trans_d]\n",
      ">Metropolis: [v_pas]\n",
      ">Metropolis: [v_crop]\n",
      ">Metropolis: [v_popDen]\n",
      ">Metropolis: [v_wind]\n",
      ">Metropolis: [v_maxTemp]\n",
      ">Metropolis: [v_drought]\n",
      ">Metropolis: [max_T]\n",
      ">Metropolis: [ex_k]\n",
      ">Metropolis: [ex_x0]\n",
      ">Metropolis: [mort_k]\n",
      ">Metropolis: [mort_x0]\n",
      ">Metropolis: [SW_k]\n",
      ">Metropolis: [SW_x0]\n",
      ">Metropolis: [MAT_k]\n",
      ">Metropolis: [MAT_x0]\n",
      ">Metropolis: [MAP_k]\n",
      ">Metropolis: [MAP_x0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='18844' class='' max='22000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      85.65% [18844/22000 09:53<01:39 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for pr_d in ['GPCC', 'CRU', 'MSWEP', 'CMORPH']: \n",
    "    for dr_v in ['MADD', 'MADM', 'MConc', 'MDDM']:\n",
    "        for ba_d in ['GFED_four_s', 'GFED_four', 'MCD_forty_five', 'meris', 'MODIS']:\n",
    "            run_pr_droughtVar(pr_d, dr_v, ba_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Likelihood definition\n",
    "\n",
    "For the sake of simplicity (and because I don't really know any better), we define the model error as normally distributed (i.i.d.) although it most likely isn't. We could make this more complicated later by defining the error as heteroscedastic, but I wouldn't bother with that until we have some idea of the convergence. We're describing the error (observations minus model predictions) as follows:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "    P(X|\\beta) &=& \\mathcal{N}(F_{burn}, \\sigma) \\\\[1em]\n",
    "    \\mathcal{N}(F_{burn}, \\sigma) &=& \\frac{N}{\\sigma\\sqrt{2\\pi}}\\exp\\left\\{\\sum_{i=1}^{N}\\left(\\frac{y_i - F_{burn, i}}{\\sigma_i}\\right)^2\\right\\}\n",
    "\\end{eqnarray}\n",
    "\n",
    "where $y_i$ is a set of observations we're attempting to optimise on. Below is the code that describes the above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Posterior sampling\n",
    "\n",
    "Because it is nigh impossible to determine the posterior solution analytically we will instead sample the information space to **infer** the posterior solutions for each of the model parameters. In this case we are using a Metropolis-Hasting step MCMC.\n",
    "\n",
    "I've tried using No-U-Turn (NUTS) sampling (which is the new kid on the block), but there are issues with it's current implementation in pymc3 (see github repo issues). Can use it once problems are ironed out - but TBH it doesn't matter if we're getting a reasonable convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pm3.traceplot(mcmc_traces);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iterations at the start are just letting the optimization settle. So we will only sample to last 5% of iterations for futher analysis. Here, exporting to netcdf for others to do their own analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cutLastX(varname, ncut = 50):\n",
    "    vals = mcmc_traces.get_values(varname)\n",
    "    def subcut(vals, r, ncut = 50):\n",
    "        cut_np = (r+1) * round(len(vals)/nChains)\n",
    "        ncut = round(len(vals) * ncut / (nChains *100))\n",
    "        return vals[(cut_np - ncut):cut_np]\n",
    "    vals = [subcut(vals, r) for r in range(nChains)]\n",
    "    return np.array(vals).flatten()\n",
    "\n",
    "varnames = mcmc_traces.varnames\n",
    "\n",
    "vals = [cutLastX(i) for i in varnames]\n",
    "\n",
    "vals = pd.DataFrame(np.array(vals).T, columns=varnames)\n",
    "vals.to_csv(param_outpath, index=False)\n",
    "\n",
    "vals.head()\n",
    "plt.plot(vals[\"mort_x0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb cimport set_trace as browser\n",
    "def cutLastX(varname, ncut = 50):\n",
    "    vals = mcmc_traces.get_values(varname)\n",
    "    browser()\n",
    "    def subcut(vals, r, ncut = 50):\n",
    "        cut_np = (r+1) * round(len(vals)/nChains)\n",
    "        ncut = round(len(vals) * ncut / (nChains *100))\n",
    "        return vals[(cut_np - ncut):cut_np]\n",
    "    vals = [subcut(vals, r) for r in range(nChains)]\n",
    "    np.array(vals).flatten()\n",
    "\n",
    "varnames = mcmc_traces.varnames\n",
    "\n",
    "vals = [cutLastX(i) for i in varnames]\n",
    "vals = pd.DataFrame(np.array(vals).T, columns=varnames)\n",
    "vals.to_csv(param_outpath, index=False)\n",
    "\n",
    "vals.head()\n",
    "plt.plot(vals[\"mort_x0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let look at the pdf of the last 5% of iterations for each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "variables2Plot = ['fuel_x0'       , 'fuel_k',\n",
    "                  'moisture_x0'   , 'moisture_k',\n",
    "                  'igntions_x0'   , 'igntions_k',\n",
    "                  'suppression_x0', 'suppression_k',\n",
    "                  'fuel_pw'       , 'fuel_pg',\n",
    "                  'cM'            , 'cMT',\n",
    "                  'cC'            ,\n",
    "                  'cP1'           , 'cP2', \n",
    "                  'cD1'           , 'cD2', 'max_f']\n",
    "\n",
    "nvar = len(variables2Plot)\n",
    "npcol = 4\n",
    "nprow = np.ceil(nvar / npcol)\n",
    "\n",
    "plt.figure(figsize=(20,5 * nprow))\n",
    "def plotVar(var1, pn):\n",
    "    plt.subplot(npcol, nprow, pn)\n",
    "    param = vals[var1]\n",
    "    \n",
    "    hist, bins = np.histogram(param, bins=50)\n",
    "    hist = 100.0 * hist / np.sum(hist)\n",
    "    bins = bins[1:] - np.diff(bins)/2\n",
    "    plt.plot(bins, hist)\n",
    "    plt.xlabel(var1)\n",
    "    \n",
    "pn = 0\n",
    "for i in variables2Plot:\n",
    "    pn = pn + 1\n",
    "    plotVar(i, pn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what to the sigmoids look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace as browser\n",
    "\n",
    "def pltVsFire(x, xlab, pnt = 'o', *args, **kw):\n",
    "    plt.plot(x, fd.fire, pnt, alpha = 0.03, *args, **kw)\n",
    "    plt.xlabel(xlab)\n",
    "    \n",
    "def np_sigmoid(x, k, x0):\n",
    "    \"\"\"\n",
    "    Sigmoid function to describe limitation using tensor\n",
    "    \"\"\"\n",
    "    return 1.0/(1.0 + np.exp(-k*(x - x0)))\n",
    "\n",
    "def returnSigmoid(x, k, x0):\n",
    "    return np_sigmoid(x, k, x0)\n",
    "    \n",
    "def meanParam(x, x0, k, kmult = 1.0):\n",
    "    x0 = np.mean(vals[x0])\n",
    "    k  = np.mean(vals[k]) * kmult\n",
    "\n",
    "    return returnSigmoid(x, k, x0)\n",
    "\n",
    "def randomParam(x, x0, k, kmult = 1.0, size = 100):\n",
    "    ps = np.random.choice(vals.shape[0], size = size, replace = False)\n",
    "    return [returnSigmoid(x, vals[k][i] * kmult, vals[x0][i]) for i in ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "####################\n",
    "## Fuel           ##\n",
    "####################\n",
    "plt.subplot(2, 2, 1)\n",
    "## scatter plot\n",
    "fp = np.mean(vals['fuel_pw'])\n",
    "fg = np.mean(vals['fuel_pg'])\n",
    "cNPP = 1.0#np.mean(vals['cNPP'])\n",
    "\n",
    "f_fuel = fuel_load(fd[\"vegCover\"].values, fd[\"alphaMax\"].values, fp, fg)\n",
    "print(f_fuel.max())\n",
    "pltVsFire(f_fuel, \"NPP (g/m$^2$)\", 'go')\n",
    "\n",
    "## Line of best fit\n",
    "#Fuel = np.arange(-6, fd.fuel.max(), 0.01)\n",
    "Fuel = np.arange(0, f_fuel.max(), 0.01)\n",
    "r_fuel = randomParam(Fuel, 'fuel_x0', 'fuel_k')\n",
    "#NPP = np.exp(Fuel)\n",
    "for r in r_fuel: plt.plot(Fuel, r, 'k', alpha=.01)\n",
    "\n",
    "## cfg plot\n",
    "#plt.xscale('log')\n",
    "#plt.xlim([0.5, fd.NPP.max()])\n",
    "\n",
    "####################\n",
    "## Moisture       ##\n",
    "####################\n",
    "plt.subplot(2, 2, 2)\n",
    "## scatter plot\n",
    "Fmax = np.mean(vals['max_f'])\n",
    "cM = np.mean(vals['cM'])\n",
    "cMT = np.mean(vals['cMT'])\n",
    "f_moisture = moisture(fd[\"alpha\"].values, fd[\"emc\"].values, fd[\"treecover\"].values, cM, cMT)\n",
    "pltVsFire(f_moisture , \"Moisture = $\\\\alpha$ + M $\\cdot$ EMC\",'bo')\n",
    "\n",
    "## Line of best fit\n",
    "mst = np.arange(0.0, f_moisture.max(), 0.05)\n",
    "r_moisture = randomParam(mst, 'moisture_x0', 'moisture_k', -1.0)\n",
    "for r in r_moisture: plt.plot(mst, r, 'k', alpha=.01)\n",
    "\n",
    "    \n",
    "plt.ylim(0, 1)\n",
    "\n",
    "####################\n",
    "## Igntions       ##\n",
    "####################\n",
    "plt.subplot(2, 2, 3)\n",
    "## scatter plot \n",
    "cP  = np.mean(vals['cP1'])\n",
    "cC  = np.mean(vals['cC' ])\n",
    "cD1 = np.mean(vals['cD1'])\n",
    "igniteMax = 10\n",
    "\n",
    "f_ignite = ignition(fd[\"lightning_ignitions\"].values, \\\n",
    "                    fd[\"cropland\"].values, \\\n",
    "                    fd[\"pasture\"].values, \\\n",
    "                    fd[\"population_density\"].values, \\\n",
    "                    cC, cP, cD1)\n",
    "#f_ignite = np.exp(f_ignite)\n",
    "pltVsFire(f_ignite, \"Ignitions events = Lightn + P $\\cdot$ Pop Dens + D1 $\\cdot$ Pasture\")\n",
    "\n",
    "## Line of best fit\n",
    "Ignite = np.arange(0.0, igniteMax, 0.1)\n",
    "#Ignite = np.exp(Ignite)\n",
    "#=Ignite = np.arange(0.0, 10000, 1)\n",
    "r_Ignite = randomParam(Ignite, 'igntions_x0', 'igntions_k')\n",
    "#yay = returnSigmoid(Ignite, 10, 1.0)\n",
    "#Ignite = np.exp(Ignite)\n",
    "for r in r_Ignite: plt.plot(Ignite, r, 'k', alpha=.01)\n",
    "\n",
    "#plt.plot(Ignite, yay, 'red')\n",
    "\n",
    "    \n",
    "## cfg plot\n",
    "#plt.xscale('log')\n",
    "plt.xlim(0, igniteMax)\n",
    "\n",
    "####################\n",
    "## Suppression    ##\n",
    "####################\n",
    "plt.subplot(2, 2, 4)\n",
    "#scatter plot\n",
    "cP2 = np.mean(vals['cP2'])\n",
    "cD2 = np.mean(vals['cD2'])\n",
    "maxF = np.mean(vals['max_f'])\n",
    "f_suppression = maxF * supression(fd[\"cropland\"].values, \\\n",
    "                           fd[\"cropland\"].values, \\\n",
    "                           fd[\"population_density\"].values, \\\n",
    "                           cP2,\n",
    "                           cD2)\n",
    "\n",
    "pltVsFire(f_suppression, \"Suppression = Cropland + D2 $\\cdot$ Pop den\")\n",
    "\n",
    "# Line of best fit\n",
    "Suppress = np.arange(0, 100, 0.01)\n",
    "r_suppression = randomParam(Suppress, 'suppression_x0', 'suppression_k', -1.0)\n",
    "for r in r_suppression: plt.plot(Suppress, r * Fmax, 'k', alpha=.01)\n",
    "\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
